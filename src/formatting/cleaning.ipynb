{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, sys\n",
    "import datetime\n",
    "from datetime import date\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import seaborn as sns\n",
    "#from ggplot import *\n",
    "\n",
    "from tableausdk import *\n",
    "from tableausdk.HyperExtract import *\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Re-factoring of the variables\n",
    "\n",
    "First of all study the different types of variables and make the necessary transformations to create columns that have correct data to study and compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: Initial directories and colnames set up\n",
      "Directory of this file is /home/agericke/crowdfunding_ml/src/formatting\n",
      "Data directory is /home/agericke/crowdfunding_ml/data\n",
      "Images directory is /home/agericke/crowdfunding_ml/src/images\n",
      "Initial columns for our model are: \n",
      "['backers_count', 'blurb', 'category', 'country', 'created_at', 'currency', 'deadline', 'goal', 'id', 'launched_at', 'location', 'pledged', 'slug', 'spotlight', 'staff_pick', 'state', 'static_usd_rate', 'usd_pledged']\n"
     ]
    }
   ],
   "source": [
    "def initial_setup():\n",
    "    \"\"\"\n",
    "    Create Initial setup of directories variables, and dataframe vars to use.\n",
    "    Returns:\n",
    "      A tuple containing:\n",
    "          - datadir:   Absolute Path to the data directory of the project.\n",
    "          - dirname:   Absolute Path of directory that contains this file.\n",
    "          - imagesdir: Absolute path of directory that contains the images.\n",
    "          - colnames: A list containing the initial colnames of the dataframe.\n",
    "    \"\"\"\n",
    "    # Initial directories set up\n",
    "    dirname = os.path.dirname(os.path.abspath('__file__'))\n",
    "    datadir =  os.path.join(os.path.abspath(os.path.join(os.path.join(dirname, os.pardir), os.pardir)), 'data')\n",
    "    imagesdir =  os.path.join(os.path.abspath(os.path.join(dirname, os.pardir)), 'images')\n",
    "    initial_colnames = sorted(['backers_count', 'blurb', 'category', 'country', 'created_at', 'currency', 'deadline', 'goal', 'id', 'launched_at', 'location', 'pledged', 'slug', 'spotlight', 'staff_pick', 'state', 'static_usd_rate', 'usd_pledged'])\n",
    "    return dirname, datadir, imagesdir, initial_colnames\n",
    "\n",
    "# 0 - Initial directories and colnames set up\n",
    "print(\"Step 0: Initial directories and colnames set up\")\n",
    "dirname, datadir, imagesdir, initial_colnames = initial_setup()\n",
    "print(\"Directory of this file is {}\".format(dirname))\n",
    "print(\"Data directory is {}\".format(datadir))\n",
    "print(\"Images directory is {}\".format(imagesdir))\n",
    "print(\"Initial columns for our model are: \\n{}\".format(initial_colnames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Step 1: Load from disk the complete Merged Dataframe.\n",
      "Completed Dataframe read from file /home/agericke/crowdfunding_ml/data/dataframe_total.pkl\n",
      "Dataframe contains 344209 projects and 18 columns for each project\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def read_from_disk(filename):\n",
    "    \"\"\"\n",
    "    Read a dataframe from a filename in disk.\n",
    "    Params:\n",
    "        filename....Path to the file.\n",
    "    Returns:\n",
    "        A pandas dataframe.\n",
    "    \"\"\"\n",
    "    return pickle.load(open(filename, 'rb'))\n",
    "\n",
    "\n",
    "def store_dataframe(dataframe, filename):\n",
    "    \"\"\"\n",
    "    Store the dataframe using pickle.\n",
    "    Params:\n",
    "        dataframe...pandas dataframe to store.\n",
    "        filename....Path to the file to store the datafram in.\n",
    "    Returns:\n",
    "        Nothing.\n",
    "    \"\"\"\n",
    "    pickle.dump(dataframe, open(filename, 'wb'))\n",
    "    \n",
    "# 1 - Load from disk the complete Merged Dataframe.\n",
    "print(\"\\n\\n\\nStep 1: Load from disk the complete Merged Dataframe.\")\n",
    "filename = os.path.join(datadir, 'dataframe_total.pkl')\n",
    "print(\"Completed Dataframe read from file {}\".format(filename))\n",
    "data = read_from_disk(filename)\n",
    "# Print summary of dataframe\n",
    "print(\"Dataframe contains {} projects and {} columns for each project\\n\".format(data.shape[0], data.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_cols(dataframe, cols_to_remove):\n",
    "    \"\"\"\n",
    "    Remove all the columns specified by the list from dataframe\n",
    "    Params:\n",
    "        cols_to_remove....List of columns we want to remove\n",
    "        dataframe.........The dataframe to remove the columns from.\n",
    "    Returns:\n",
    "        A dataframe with only the columns we want.\n",
    "    \"\"\"\n",
    "    dataframe.drop(cols_to_remove, inplace=True, axis=1)\n",
    "    print(\"Succesfully removed columns {}\".format(cols_to_remove))\n",
    "    return dataframe\n",
    "\n",
    "def categorical_with_per_count(dataframe, feature):\n",
    "    \"\"\"\n",
    "    Calculate frequency of the categorical feature with % and count base.\n",
    "    Sorted on the descending order.\n",
    "\n",
    "    Params:\n",
    "        dataframe.....Pandas dataframe from where to pick the data.\n",
    "        feature.......Column for which we want to calculate the data for.\n",
    "    \"\"\"\n",
    "    \n",
    "    # calculate frequency on % and value\n",
    "    freq_merged = pd.concat([dataframe[feature].value_counts(normalize=True) * 100,\n",
    "                             dataframe[feature].value_counts(normalize=False)], axis=1)\n",
    "    # rename columns\n",
    "    freq_merged.columns = [feature + '_%', feature + '_count']\n",
    "    return freq_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>backers_count</th>\n",
       "      <th>blurb</th>\n",
       "      <th>category</th>\n",
       "      <th>country</th>\n",
       "      <th>created_at</th>\n",
       "      <th>currency</th>\n",
       "      <th>deadline</th>\n",
       "      <th>goal</th>\n",
       "      <th>id</th>\n",
       "      <th>launched_at</th>\n",
       "      <th>location</th>\n",
       "      <th>pledged</th>\n",
       "      <th>slug</th>\n",
       "      <th>spotlight</th>\n",
       "      <th>staff_pick</th>\n",
       "      <th>state</th>\n",
       "      <th>static_usd_rate</th>\n",
       "      <th>usd_pledged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2967</th>\n",
       "      <td>1</td>\n",
       "      <td>To create art, an artist must have their tools...</td>\n",
       "      <td>{\"urls\":{\"web\":{\"discover\":\"http://www.kicksta...</td>\n",
       "      <td>US</td>\n",
       "      <td>1428557824</td>\n",
       "      <td>USD</td>\n",
       "      <td>1429770591</td>\n",
       "      <td>400.0</td>\n",
       "      <td>2141932586</td>\n",
       "      <td>1428560991</td>\n",
       "      <td>{\"country\":\"US\",\"urls\":{\"web\":{\"discover\":\"htt...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>tools-of-the-trade</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>canceled</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4106</th>\n",
       "      <td>0</td>\n",
       "      <td>Firestarter kits for revolutionaries! markers,...</td>\n",
       "      <td>{\"urls\":{\"web\":{\"discover\":\"http://www.kicksta...</td>\n",
       "      <td>US</td>\n",
       "      <td>1453437274</td>\n",
       "      <td>USD</td>\n",
       "      <td>1455244263</td>\n",
       "      <td>63000.0</td>\n",
       "      <td>569937661</td>\n",
       "      <td>1453948263</td>\n",
       "      <td>{\"country\":\"US\",\"urls\":{\"web\":{\"discover\":\"htt...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>project-flint</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>live</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>3</td>\n",
       "      <td>Sophie is an aspiring artist! She will be 5 in...</td>\n",
       "      <td>{\"urls\":{\"web\":{\"discover\":\"http://www.kicksta...</td>\n",
       "      <td>US</td>\n",
       "      <td>1409805071</td>\n",
       "      <td>USD</td>\n",
       "      <td>1412906207</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1619161443</td>\n",
       "      <td>1410314207</td>\n",
       "      <td>{\"country\":\"US\",\"urls\":{\"web\":{\"discover\":\"htt...</td>\n",
       "      <td>120.0</td>\n",
       "      <td>4-year-old-creates-art-for-her-future-education</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>failed</td>\n",
       "      <td>1.0</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      backers_count                                              blurb  \\\n",
       "2967              1  To create art, an artist must have their tools...   \n",
       "4106              0  Firestarter kits for revolutionaries! markers,...   \n",
       "635               3  Sophie is an aspiring artist! She will be 5 in...   \n",
       "\n",
       "                                               category country  created_at  \\\n",
       "2967  {\"urls\":{\"web\":{\"discover\":\"http://www.kicksta...      US  1428557824   \n",
       "4106  {\"urls\":{\"web\":{\"discover\":\"http://www.kicksta...      US  1453437274   \n",
       "635   {\"urls\":{\"web\":{\"discover\":\"http://www.kicksta...      US  1409805071   \n",
       "\n",
       "     currency    deadline     goal          id  launched_at  \\\n",
       "2967      USD  1429770591    400.0  2141932586   1428560991   \n",
       "4106      USD  1455244263  63000.0   569937661   1453948263   \n",
       "635       USD  1412906207   1000.0  1619161443   1410314207   \n",
       "\n",
       "                                               location  pledged  \\\n",
       "2967  {\"country\":\"US\",\"urls\":{\"web\":{\"discover\":\"htt...     20.0   \n",
       "4106  {\"country\":\"US\",\"urls\":{\"web\":{\"discover\":\"htt...      0.0   \n",
       "635   {\"country\":\"US\",\"urls\":{\"web\":{\"discover\":\"htt...    120.0   \n",
       "\n",
       "                                                 slug  spotlight  staff_pick  \\\n",
       "2967                               tools-of-the-trade      False       False   \n",
       "4106                                    project-flint      False       False   \n",
       "635   4-year-old-creates-art-for-her-future-education      False       False   \n",
       "\n",
       "         state  static_usd_rate  usd_pledged  \n",
       "2967  canceled              1.0         20.0  \n",
       "4106      live              1.0          0.0  \n",
       "635     failed              1.0        120.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Step 2: Look for missing values for every row and print summary.\n",
      "                 Total_count   %_count\n",
      "location                1072  0.311439\n",
      "blurb                     18  0.005229\n",
      "usd_pledged                0  0.000000\n",
      "goal                       0  0.000000\n",
      "category                   0  0.000000\n",
      "country                    0  0.000000\n",
      "created_at                 0  0.000000\n",
      "currency                   0  0.000000\n",
      "deadline                   0  0.000000\n",
      "id                         0  0.000000\n",
      "static_usd_rate            0  0.000000\n",
      "launched_at                0  0.000000\n",
      "pledged                    0  0.000000\n",
      "slug                       0  0.000000\n",
      "spotlight                  0  0.000000\n",
      "staff_pick                 0  0.000000\n",
      "state                      0  0.000000\n",
      "backers_count              0  0.000000\n",
      "As we can see, we have very low percentage of missing values,the highest column with missing values is location column with only a 0.31%, so we decided to drop the missing values.\n",
      "Also, studying the missing data, we discover that out of 1091 rows with missing data: \n",
      "\n",
      "United States     1087\n",
      "Great Britain     2\n",
      "Denmark           1\n",
      "Austria           1\n",
      "\n",
      "The distribution of the missing values across the main_category variable is:\n",
      "\n",
      "art             118\n",
      "comics           14\n",
      "crafts            9\n",
      "dance            18\n",
      "design           12\n",
      "fashion           6\n",
      "film & video    279\n",
      "food            10\n",
      "games            49\n",
      "journalism       55\n",
      "music           258\n",
      "photography      49\n",
      "publishing      141\n",
      "technology       51\n",
      "theater          22\n"
     ]
    }
   ],
   "source": [
    "def check_missing_values_and_drop(data, drop=False):\n",
    "    \"\"\"\n",
    "    Check the number of missing values that we have. Notice that this function\n",
    "    will count \n",
    "    Params:\n",
    "        data....Dataframe to check the missing values.\n",
    "        drop....Boolean to indicate if we want to drop missing values or not.\n",
    "    Returns:\n",
    "        Prints a summary of the number and % of missing values.\n",
    "        The dataframe with no missing values\n",
    "    \"\"\"\n",
    "    #dataMis=data[data.isnull().any(axis=1)]\n",
    "    #print(dataMis.groupby('country').country.count())\n",
    "    total_rows = data.shape[0]\n",
    "    #isna() sets True NA values and numpy.NaN. Empty strings or infinites are not set as True.\n",
    "    na_col_counts = data.isna().sum().sort_values(ascending = False)\n",
    "    freq_merged = pd.concat([na_col_counts, (na_col_counts/total_rows)*100], axis=1)\n",
    "    freq_merged.columns = ['Total_count', '%_count']\n",
    "    print(freq_merged)\n",
    "\n",
    "    if drop:\n",
    "        data = data.dropna()\n",
    "    \n",
    "    return data\n",
    "    # TODO: See if we can check the missing indexes for each column and run a study on them.\n",
    "    # TODO: Run experiments to try to identify is the missing values are mainly because of a reason or one type of project, or specific to one period of time (see if they are missing at random, missing not at random...)\n",
    "\n",
    "# 2 - Look for missing values for every row and print summary.\n",
    "print(\"\\n\\n\\nStep 2: Look for missing values for every row and print summary.\")\n",
    "data = check_missing_values_and_drop(data, False)\n",
    "print(\"As we can see, we have very low percentage of missing values,the highest column with missing \\\n",
    "values is location column with only a 0.31%, so we decided to drop the missing values.\")\n",
    "print(\"Also, studying the missing data, we discover that out of 1091 rows with missing data: \\n\")\n",
    "print(\"United States     1087\\nGreat Britain     2\\nDenmark           1\\nAustria           1\\n\")\n",
    "print(\"The distribution of the missing values across the main_category variable is:\\n\")\n",
    "print(\"art             118\\ncomics           14\\ncrafts            9\\ndance            18\\ndesign           12\\nfashion           6\\nfilm & video    279\\nfood            10\\ngames            49\\njournalism       55\\nmusic           258\\nphotography      49\\npublishing      141\\ntechnology       51\\ntheater          22\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "backers_count         0\n",
       "blurb                18\n",
       "category              0\n",
       "country               0\n",
       "created_at            0\n",
       "currency              0\n",
       "deadline              0\n",
       "goal                  0\n",
       "id                    0\n",
       "launched_at           0\n",
       "location           1072\n",
       "pledged               0\n",
       "slug                  0\n",
       "spotlight             0\n",
       "staff_pick            0\n",
       "state                 0\n",
       "static_usd_rate       0\n",
       "usd_pledged           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Total_count   %_count\n",
      "location                1072  0.311439\n",
      "blurb                     18  0.005229\n",
      "usd_pledged                0  0.000000\n",
      "goal                       0  0.000000\n",
      "category                   0  0.000000\n",
      "country                    0  0.000000\n",
      "created_at                 0  0.000000\n",
      "currency                   0  0.000000\n",
      "deadline                   0  0.000000\n",
      "id                         0  0.000000\n",
      "static_usd_rate            0  0.000000\n",
      "launched_at                0  0.000000\n",
      "pledged                    0  0.000000\n",
      "slug                       0  0.000000\n",
      "spotlight                  0  0.000000\n",
      "staff_pick                 0  0.000000\n",
      "state                      0  0.000000\n",
      "backers_count              0  0.000000\n"
     ]
    }
   ],
   "source": [
    "df_null = data[data.isna().any(axis=1)]\n",
    "data = check_missing_values_and_drop(data, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 343119 entries, 2967 to 3281\n",
      "Data columns (total 18 columns):\n",
      "backers_count      343119 non-null int64\n",
      "blurb              343119 non-null object\n",
      "category           343119 non-null object\n",
      "country            343119 non-null object\n",
      "created_at         343119 non-null int64\n",
      "currency           343119 non-null object\n",
      "deadline           343119 non-null int64\n",
      "goal               343119 non-null float64\n",
      "id                 343119 non-null int64\n",
      "launched_at        343119 non-null int64\n",
      "location           343119 non-null object\n",
      "pledged            343119 non-null float64\n",
      "slug               343119 non-null object\n",
      "spotlight          343119 non-null bool\n",
      "staff_pick         343119 non-null bool\n",
      "state              343119 non-null object\n",
      "static_usd_rate    343119 non-null float64\n",
      "usd_pledged        343119 non-null float64\n",
      "dtypes: bool(2), float64(4), int64(5), object(7)\n",
      "memory usage: 45.2+ MB\n",
      "None\n",
      "bool       2\n",
      "float64    4\n",
      "int64      5\n",
      "object     7\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.info())\n",
    "print(data.get_dtype_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change state column to result\n",
    "data['result'] = data['state']\n",
    "data.drop('state', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2967       400.00000\n",
       "4106     63000.00000\n",
       "635       1000.00000\n",
       "138       7293.70130\n",
       "1456      7137.31045\n",
       "1457    176409.77750\n",
       "1458      5000.00000\n",
       "1459     40000.00000\n",
       "1475      1500.00000\n",
       "1476    150000.00000\n",
       "Name: goal_usd, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create goal_usd\n",
    "data['goal_usd'] = data['goal']*data['static_usd_rate']\n",
    "data.goal_usd.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2967        20.000000\n",
       "4106         0.000000\n",
       "635        120.000000\n",
       "138     537049.814122\n",
       "1456         0.000000\n",
       "1457         0.000000\n",
       "1458         0.000000\n",
       "1459      2180.000000\n",
       "1475         0.000000\n",
       "1476        31.000000\n",
       "Name: pledged_usd, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create pledged_usd\n",
    "data['pledged_usd'] = data['pledged']*data['static_usd_rate']\n",
    "data.pledged_usd.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    3.431190e+05\n",
      "mean     1.684488e-13\n",
      "std      3.711379e-12\n",
      "min      0.000000e+00\n",
      "25%      0.000000e+00\n",
      "50%      0.000000e+00\n",
      "75%      0.000000e+00\n",
      "max      9.313226e-10\n",
      "dtype: float64\n",
      "Succesfully removed columns ['goal', 'pledged', 'static_usd_rate', 'usd_pledged']\n"
     ]
    }
   ],
   "source": [
    "# Study differences from calculated to the value we had.\n",
    "print(abs(data['usd_pledged'] - data['pledged_usd']).describe())\n",
    "\n",
    "# Remove not any more useful cols.\n",
    "data = remove_cols(data, ['goal', 'pledged', 'static_usd_rate', 'usd_pledged'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create date type variables for created_at, launched_at and deadline\n",
    "data['launched_at'] = pd.to_datetime(data['launched_at'], unit='s')\n",
    "data['deadline'] = pd.to_datetime(data['deadline'], unit='s')\n",
    "data['created_at'] = pd.to_datetime(data['created_at'], unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['backers_count', 'blurb', 'category', 'country', 'created_at',\n",
       "       'currency', 'deadline', 'id', 'launched_at', 'location', 'slug',\n",
       "       'spotlight', 'staff_pick', 'result', 'goal_usd', 'pledged_usd'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.get_dtype_counts()\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tableausdk.Exceptions import *\n",
    "\n",
    "# You cannot delete or append to a .tde file if it is opened in Tableau\n",
    "def to_tde(dataframe, filename, tb_name='Kickstarter'):\n",
    "    \"\"\"\n",
    "    Function for creating an hyper dataset for Tableua from the pandas dataframe.\n",
    "    \n",
    "    Params:\n",
    "        - dataframe.....Pandas dataframe to create the extract from.\n",
    "        - filename......Path to the file where we will store the .hyper extract.\n",
    "        - tb_name.......Name of the table to be created. (Deafault: Kickstarter)\n",
    "        \n",
    "    Returns:\n",
    "        Nothing\n",
    "    \"\"\"    \n",
    "    # 0 - Initialize extract API\n",
    "    ExtractAPI.initialize()\n",
    "\n",
    "    # Step 1: Create the Extract File\n",
    "    dataExtract = Extract(filename)\n",
    "\n",
    "    if dataExtract.hasTable(tb_name):\n",
    "        return print(\"tde already exist use another name\")\n",
    "\n",
    "    # Step 2: Create the table definition\n",
    "    if (not dataExtract.hasTable(tb_name)):\n",
    "        dataSchema = TableDefinition()\n",
    "        dataSchema.addColumn('backers_count', Type.INTEGER)\n",
    "        dataSchema.addColumn('blurb', Type.UNICODE_STRING)\n",
    "        dataSchema.addColumn('category', Type.CHAR_STRING)\n",
    "        dataSchema.addColumn('country', Type.CHAR_STRING)\n",
    "        dataSchema.addColumn('created_at', Type.DATETIME)\n",
    "        dataSchema.addColumn('currency', Type.CHAR_STRING)\n",
    "        dataSchema.addColumn('deadline', Type.DATETIME)\n",
    "        dataSchema.addColumn('id', Type.INTEGER)\n",
    "        dataSchema.addColumn('launched_at', Type.DATETIME)\n",
    "        dataSchema.addColumn('location', Type.UNICODE_STRING)\n",
    "        dataSchema.addColumn('slug', Type.UNICODE_STRING)\n",
    "        dataSchema.addColumn('spotlight', Type.BOOLEAN)\n",
    "        dataSchema.addColumn('staff_pick', Type.BOOLEAN)\n",
    "        dataSchema.addColumn('state', Type.CHAR_STRING)\n",
    "        dataSchema.addColumn('goal_usd', Type.DOUBLE)\n",
    "        dataSchema.addColumn('pledged_usd', Type.DOUBLE)\n",
    "\n",
    "        # Step 3: Create a table in the image of the table definition\n",
    "        table = dataExtract.addTable(tb_name, dataSchema)\n",
    "\n",
    "    # Step 4: Create rows and insert them one by one\n",
    "    newRow = Row(dataSchema)\n",
    "    for i in range(0, len(dataframe)):\n",
    "        newRow.setInteger(0, dataframe['backers_count'].iloc[i])\n",
    "        newRow.setString(1, dataframe['blurb'].iloc[i])\n",
    "        newRow.setCharString(2, dataframe['category'].iloc[i])\n",
    "        newRow.setCharString(3, dataframe['country'].iloc[i])\n",
    "        newRow.setDateTime(4, dataframe['created_at'].iloc[i].year, dataframe['created_at'].iloc[i].month, dataframe['created_at'].iloc[i].day, dataframe['created_at'].iloc[i].hour, dataframe['created_at'].iloc[i].minute, dataframe['created_at'].iloc[i].second, dataframe['created_at'].iloc[i].microsecond)\n",
    "        newRow.setCharString(5, dataframe['currency'].iloc[i])\n",
    "        newRow.setDateTime(6, dataframe['deadline'].iloc[i].year, dataframe['deadline'].iloc[i].month, dataframe['deadline'].iloc[i].day, dataframe['deadline'].iloc[i].hour, dataframe['deadline'].iloc[i].minute, dataframe['deadline'].iloc[i].second, dataframe['deadline'].iloc[i].microsecond)\n",
    "        newRow.setInteger(7, dataframe['id'].iloc[i])\n",
    "        newRow.setDateTime(8, dataframe['launched_at'].iloc[i].year, dataframe['launched_at'].iloc[i].month, dataframe['launched_at'].iloc[i].day, dataframe['launched_at'].iloc[i].hour, dataframe['launched_at'].iloc[i].minute, dataframe['launched_at'].iloc[i].second, dataframe['launched_at'].iloc[i].microsecond)\n",
    "        newRow.setString(9, dataframe['location'].iloc[i])\n",
    "        newRow.setString(10, dataframe['slug'].iloc[i])\n",
    "        newRow.setBoolean(11, dataframe['spotlight'].iloc[i])\n",
    "        newRow.setBoolean(12, dataframe['staff_pick'].iloc[i])\n",
    "        newRow.setCharString(13, dataframe['state'].iloc[i])\n",
    "        newRow.setDouble(14, dataframe['goal_usd'].iloc[i])\n",
    "        newRow.setDouble(15, dataframe['pledged_usd'].iloc[i])\n",
    "        \n",
    "        table.insert(newRow)\n",
    "\n",
    "    # Step 5: Close the tde\n",
    "    dataExtract.close()\n",
    "    \n",
    "    # Step 6: Close the Tableau Extract API\n",
    "    ExtractAPI.cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_tde(data, os.path.join(datadir, 'kickstarter.hyper'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succesfully created columns category and subcategory\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>backers_count</th>\n",
       "      <th>blurb</th>\n",
       "      <th>country</th>\n",
       "      <th>created_at</th>\n",
       "      <th>currency</th>\n",
       "      <th>deadline</th>\n",
       "      <th>id</th>\n",
       "      <th>launched_at</th>\n",
       "      <th>location</th>\n",
       "      <th>slug</th>\n",
       "      <th>spotlight</th>\n",
       "      <th>staff_pick</th>\n",
       "      <th>result</th>\n",
       "      <th>goal_usd</th>\n",
       "      <th>pledged_usd</th>\n",
       "      <th>main_category</th>\n",
       "      <th>sub_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2967</th>\n",
       "      <td>1</td>\n",
       "      <td>To create art, an artist must have their tools...</td>\n",
       "      <td>US</td>\n",
       "      <td>2015-04-09 05:37:04</td>\n",
       "      <td>USD</td>\n",
       "      <td>2015-04-23 06:29:51</td>\n",
       "      <td>2141932586</td>\n",
       "      <td>2015-04-09 06:29:51</td>\n",
       "      <td>{\"country\":\"US\",\"urls\":{\"web\":{\"discover\":\"htt...</td>\n",
       "      <td>tools-of-the-trade</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>canceled</td>\n",
       "      <td>400.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>art</td>\n",
       "      <td>digital-art</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4106</th>\n",
       "      <td>0</td>\n",
       "      <td>Firestarter kits for revolutionaries! markers,...</td>\n",
       "      <td>US</td>\n",
       "      <td>2016-01-22 04:34:34</td>\n",
       "      <td>USD</td>\n",
       "      <td>2016-02-12 02:31:03</td>\n",
       "      <td>569937661</td>\n",
       "      <td>2016-01-28 02:31:03</td>\n",
       "      <td>{\"country\":\"US\",\"urls\":{\"web\":{\"discover\":\"htt...</td>\n",
       "      <td>project-flint</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>live</td>\n",
       "      <td>63000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>crafts</td>\n",
       "      <td>printing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      backers_count                                              blurb  \\\n",
       "2967              1  To create art, an artist must have their tools...   \n",
       "4106              0  Firestarter kits for revolutionaries! markers,...   \n",
       "\n",
       "     country          created_at currency            deadline          id  \\\n",
       "2967      US 2015-04-09 05:37:04      USD 2015-04-23 06:29:51  2141932586   \n",
       "4106      US 2016-01-22 04:34:34      USD 2016-02-12 02:31:03   569937661   \n",
       "\n",
       "             launched_at                                           location  \\\n",
       "2967 2015-04-09 06:29:51  {\"country\":\"US\",\"urls\":{\"web\":{\"discover\":\"htt...   \n",
       "4106 2016-01-28 02:31:03  {\"country\":\"US\",\"urls\":{\"web\":{\"discover\":\"htt...   \n",
       "\n",
       "                    slug  spotlight  staff_pick    result  goal_usd  \\\n",
       "2967  tools-of-the-trade      False       False  canceled     400.0   \n",
       "4106       project-flint      False       False      live   63000.0   \n",
       "\n",
       "      pledged_usd main_category sub_category  \n",
       "2967         20.0           art  digital-art  \n",
       "4106          0.0        crafts     printing  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def obtain_cat_and_subcat_for_row(row):\n",
    "    \"\"\"\n",
    "    Obtain category and subcategory of a row. notice that if subcategory not present,\n",
    "    this will set it to none.\n",
    "    Params:\n",
    "        row....The dataframe row.\n",
    "    Returns:\n",
    "        A tuple containing:\n",
    "            - category: Value for obtained category.\n",
    "            - subcategory: Value for obtained subcategory, and None if not present.\n",
    "    \"\"\"\n",
    "    # Convert string to dict\n",
    "    cat_split = json.loads(row['category'])['slug'].split('/')\n",
    "    # Save category and subcategory\n",
    "    category = cat_split[0]\n",
    "    subcategory = \"\"\n",
    "    \n",
    "    if len(cat_split)>1:\n",
    "        # There is a sucategory\n",
    "        subcategory = cat_split[1]\n",
    "    \n",
    "    return (category, subcategory)\n",
    "    \n",
    "\n",
    "def create_cat_and_subcat(data):\n",
    "    \"\"\"\n",
    "    Save in a new column the category and subcategory extracted from the category column.\n",
    "    Params:\n",
    "        data.....Dataframe.\n",
    "    Returns:\n",
    "        A dataframe with category and subcategory vars created.¡ for each row.\n",
    "    \"\"\"\n",
    "    cat_subcat = data.apply(obtain_cat_and_subcat_for_row, axis=1)\n",
    "    data['main_category'] = [c[0].lower().strip().replace(' ','-') for c in cat_subcat]\n",
    "    data['sub_category'] = [c[1].lower().strip().replace(' ','-') for c in cat_subcat]\n",
    "    data.drop('category', inplace=True, axis=1)\n",
    "    print('Succesfully created columns category and subcategory')\n",
    "    \n",
    "    return data\n",
    "\n",
    "data = create_cat_and_subcat(data)\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_location_vars_for_row(row):\n",
    "    \"\"\"\n",
    "    Obtain country, state and city.\n",
    "    Params:\n",
    "        row....The dataframe row.\n",
    "    Returns:\n",
    "        A tuple containing:\n",
    "            - country: Country oobtained.\n",
    "            - state: State obtained.\n",
    "            - loc_type: Type of location obtained.\n",
    "    \"\"\"\n",
    "    # Convert string to dict\n",
    "    loc_dict = json.loads(row['location'])\n",
    "    country = loc_dict['country']\n",
    "    state = loc_dict['state']\n",
    "    city =  loc_dict['name']\n",
    "    \n",
    "    return (country, state, city)\n",
    "    \n",
    "\n",
    "def create_location_vars(data):\n",
    "    \"\"\"\n",
    "    Save in a new column the country, state and location type extracted from the location column.\n",
    "    Params:\n",
    "        data.....Dataframe.\n",
    "    Returns:\n",
    "        A dataframe with country, state and location vars created for each row.\n",
    "    \"\"\"\n",
    "    location_vars = data.apply(obtain_location_vars_for_row, axis=1)\n",
    "    data['country2'] = [c[0] for c in location_vars]\n",
    "    data['state'] = [c[1] for c in location_vars]\n",
    "    data['city'] = [c[2] for c in location_vars]\n",
    "    #data.drop(\"location\", inplace=True, axis=1)\n",
    "    print(\"Succesfully created columns country, region_state and type\")\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succesfully created columns country, region_state and type\n"
     ]
    }
   ],
   "source": [
    "df2 = create_location_vars(data)\n",
    "data[data.country != data.country2]\n",
    "# After some comparison we determine that country2 is more realiable than country.\n",
    "data['country'] = data['country2']\n",
    "data.drop('country2', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA (Exploratory Data Analysis)\n",
    "\n",
    "After we have set all columns correctly we proceed to perform a EDA study of all vars. This study will cover:\n",
    "\n",
    "- Study of general data types, unique identifier and missing values.\n",
    "- Perform per var analysis of ranges, check categorical variables.\n",
    "- Per variable target variable analysis.\n",
    "- Possible variable relations.\n",
    "- Variable cleaning.\n",
    "- Dataset set-up for modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 343119 entries, 2967 to 3281\n",
      "Data columns (total 19 columns):\n",
      "backers_count    343119 non-null int64\n",
      "blurb            343119 non-null object\n",
      "country          343119 non-null object\n",
      "created_at       343119 non-null datetime64[ns]\n",
      "currency         343119 non-null object\n",
      "deadline         343119 non-null datetime64[ns]\n",
      "id               343119 non-null int64\n",
      "launched_at      343119 non-null datetime64[ns]\n",
      "location         343119 non-null object\n",
      "slug             343119 non-null object\n",
      "spotlight        343119 non-null bool\n",
      "staff_pick       343119 non-null bool\n",
      "result           343119 non-null object\n",
      "goal_usd         343119 non-null float64\n",
      "pledged_usd      343119 non-null float64\n",
      "main_category    343119 non-null object\n",
      "sub_category     343119 non-null object\n",
      "state            343023 non-null object\n",
      "city             343119 non-null object\n",
      "dtypes: bool(2), datetime64[ns](3), float64(2), int64(2), object(10)\n",
      "memory usage: 47.8+ MB\n",
      "None\n",
      "\n",
      "\n",
      "int64              2\n",
      "object            10\n",
      "datetime64[ns]     3\n",
      "bool               2\n",
      "float64            2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 1 - Overview of the data.\n",
    "print(data.info())\n",
    "print('\\n')\n",
    "print(data.get_dtype_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 - Check key for the data\n",
    "# Check that id columns can be used as a key and that has only one count per value\n",
    "(data.id.value_counts() > 1).sum()\n",
    "# After we check that can be used as key we set it as index.\n",
    "data.set_index('id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 - Check new missing values\n",
    "data.isna().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if blurb lenght has any power over project success.\n",
    "\n",
    "# Study backers_count variable. (Scatterplot and check medium value of backer.)\n",
    "\n",
    "# Study per country rates of success.\n",
    "\n",
    "# Study per year, month, time of the year and day of the week rate of success for creation date.\n",
    "\n",
    "# Study per currency rate of success.\n",
    "\n",
    "# Study per year, month, time of the year and day of the week rate of success for creation date."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
