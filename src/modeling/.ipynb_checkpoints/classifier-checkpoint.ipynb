{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import math\n",
    "from datetime import date\n",
    "import time\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "from itertools import product\n",
    "from math import log\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "#%matplotlib inline\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELING PROCESS\n",
    "\n",
    "The modeling process will consist of the following phases:\n",
    "\n",
    "1. Normalize data\n",
    "2. Build model\n",
    "3. Compute cross-validation accuracy\n",
    "4. Tune model\n",
    "5. Repeat\n",
    "6. **Report accuracy on new data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_setup():\n",
    "    \"\"\"Create Initial setup of directories variables, and dataframe vars to use.\n",
    "    Returns:\n",
    "        A tuple containing:\n",
    "            - datadir....Absolute Path to the data directory of the project.\n",
    "            - dirname....Absolute Path of directory that contains this file.\n",
    "            - imagesdir..Absolute path of directory that contains the images.\n",
    "    \"\"\"\n",
    "    dirname = os.path.dirname(os.path.abspath('__file__'))\n",
    "    datadir =  os.path.join(\n",
    "                os.path.abspath(os.path.join(os.path.join(dirname, os.pardir), os.pardir)), \n",
    "                'data'\n",
    "            )\n",
    "    imagesdir =  os.path.join(os.path.abspath(os.path.join(dirname, os.pardir)), 'images')\n",
    "    return dirname, datadir, imagesdir\n",
    "\n",
    "\n",
    "def read_from_disk(filename):\n",
    "    \"\"\"Read a dataframe from a filename in disk.\n",
    "    Args:\n",
    "        filename....Path to the file.\n",
    "    Returns:\n",
    "        A pandas dataframe.\n",
    "    \"\"\"\n",
    "    return pickle.load(open(filename, 'rb'))\n",
    "\n",
    "\n",
    "def store_model(dataframe, filename):\n",
    "    \"\"\"Store model using pickle.\n",
    "    Args:\n",
    "        dataframe...pandas dataframe to store.\n",
    "        filename....Path to the file to store the datafram in.\n",
    "    Returns:\n",
    "        Nothing.\n",
    "    \"\"\"\n",
    "    pickle.dump(dataframe, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: Initial directories and colnames set up\n",
      "Directory of this file is /home/agericke/crowdfunding_ml/src/modeling\n",
      "Data directory is /home/agericke/crowdfunding_ml/data\n",
      "Images directory is /home/agericke/crowdfunding_ml/src/images\n"
     ]
    }
   ],
   "source": [
    "# 0 - Initial directories and colnames set up\n",
    "print(\"Step 0: Initial directories and colnames set up\")\n",
    "dirname, datadir, imagesdir = initial_setup()\n",
    "print(\"Directory of this file is {}\".format(dirname))\n",
    "print(\"Data directory is {}\".format(datadir))\n",
    "print(\"Images directory is {}\".format(imagesdir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  0. Load data and select variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>staff_pick</th>\n",
       "      <th>result</th>\n",
       "      <th>goal_usd</th>\n",
       "      <th>pledged_usd</th>\n",
       "      <th>main_category</th>\n",
       "      <th>state</th>\n",
       "      <th>ln(goal_usd)</th>\n",
       "      <th>goal_usd_bin</th>\n",
       "      <th>duration_in_days_bin</th>\n",
       "      <th>weekday_launch</th>\n",
       "      <th>weekend_launch</th>\n",
       "      <th>month_launch</th>\n",
       "      <th>num_competitors</th>\n",
       "      <th>num_competitors_bin</th>\n",
       "      <th>num_competitors_staffpick</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>launched_at</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009-04-28 11:55:41</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>3329.00</td>\n",
       "      <td>journalism</td>\n",
       "      <td>NY</td>\n",
       "      <td>8.006368</td>\n",
       "      <td>(0.0, 40000.0]</td>\n",
       "      <td>(0.0, 29.0]</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(0.0, 10.0]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-29 03:26:32</th>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>15.00</td>\n",
       "      <td>music</td>\n",
       "      <td>IL</td>\n",
       "      <td>5.703782</td>\n",
       "      <td>(0.0, 40000.0]</td>\n",
       "      <td>(0.0, 29.0]</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(0.0, 10.0]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-29 20:08:13</th>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>41.00</td>\n",
       "      <td>design</td>\n",
       "      <td>NY</td>\n",
       "      <td>6.461468</td>\n",
       "      <td>(0.0, 40000.0]</td>\n",
       "      <td>(45.0, inf]</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(0.0, 10.0]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-29 21:11:15</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1820.00</td>\n",
       "      <td>technology</td>\n",
       "      <td>NY</td>\n",
       "      <td>6.214608</td>\n",
       "      <td>(0.0, 40000.0]</td>\n",
       "      <td>(45.0, inf]</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(0.0, 10.0]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-29 23:32:55</th>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>500.0</td>\n",
       "      <td>501.66</td>\n",
       "      <td>film-&amp;-video</td>\n",
       "      <td>IN</td>\n",
       "      <td>6.214608</td>\n",
       "      <td>(0.0, 40000.0]</td>\n",
       "      <td>(29.0, 45.0]</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(0.0, 10.0]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-30 20:22:43</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>6575.00</td>\n",
       "      <td>theater</td>\n",
       "      <td>NY</td>\n",
       "      <td>8.699515</td>\n",
       "      <td>(0.0, 40000.0]</td>\n",
       "      <td>(29.0, 45.0]</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(0.0, 10.0]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-30 20:23:22</th>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>10145.00</td>\n",
       "      <td>theater</td>\n",
       "      <td>NY</td>\n",
       "      <td>9.210340</td>\n",
       "      <td>(0.0, 40000.0]</td>\n",
       "      <td>(45.0, inf]</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>(0.0, 10.0]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-01 03:06:19</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>500.0</td>\n",
       "      <td>575.00</td>\n",
       "      <td>theater</td>\n",
       "      <td>VA</td>\n",
       "      <td>6.214608</td>\n",
       "      <td>(0.0, 40000.0]</td>\n",
       "      <td>(29.0, 45.0]</td>\n",
       "      <td>Friday</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(0.0, 10.0]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-01 12:22:21</th>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>25.00</td>\n",
       "      <td>art</td>\n",
       "      <td>NY</td>\n",
       "      <td>7.600902</td>\n",
       "      <td>(0.0, 40000.0]</td>\n",
       "      <td>(29.0, 45.0]</td>\n",
       "      <td>Friday</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(0.0, 10.0]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-01 15:44:25</th>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>4100.60</td>\n",
       "      <td>music</td>\n",
       "      <td>LA</td>\n",
       "      <td>8.294050</td>\n",
       "      <td>(0.0, 40000.0]</td>\n",
       "      <td>(29.0, 45.0]</td>\n",
       "      <td>Friday</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(0.0, 10.0]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     staff_pick  result  goal_usd  pledged_usd main_category  \\\n",
       "launched_at                                                                    \n",
       "2009-04-28 11:55:41        True       1    3000.0      3329.00    journalism   \n",
       "2009-04-29 03:26:32       False       0     300.0        15.00         music   \n",
       "2009-04-29 20:08:13       False       0     640.0        41.00        design   \n",
       "2009-04-29 21:11:15        True       1     500.0      1820.00    technology   \n",
       "2009-04-29 23:32:55       False       1     500.0       501.66  film-&-video   \n",
       "2009-04-30 20:22:43        True       1    6000.0      6575.00       theater   \n",
       "2009-04-30 20:23:22       False       1   10000.0     10145.00       theater   \n",
       "2009-05-01 03:06:19        True       1     500.0       575.00       theater   \n",
       "2009-05-01 12:22:21       False       0    2000.0        25.00           art   \n",
       "2009-05-01 15:44:25        True       1    4000.0      4100.60         music   \n",
       "\n",
       "                    state  ln(goal_usd)    goal_usd_bin duration_in_days_bin  \\\n",
       "launched_at                                                                    \n",
       "2009-04-28 11:55:41    NY      8.006368  (0.0, 40000.0]          (0.0, 29.0]   \n",
       "2009-04-29 03:26:32    IL      5.703782  (0.0, 40000.0]          (0.0, 29.0]   \n",
       "2009-04-29 20:08:13    NY      6.461468  (0.0, 40000.0]          (45.0, inf]   \n",
       "2009-04-29 21:11:15    NY      6.214608  (0.0, 40000.0]          (45.0, inf]   \n",
       "2009-04-29 23:32:55    IN      6.214608  (0.0, 40000.0]         (29.0, 45.0]   \n",
       "2009-04-30 20:22:43    NY      8.699515  (0.0, 40000.0]         (29.0, 45.0]   \n",
       "2009-04-30 20:23:22    NY      9.210340  (0.0, 40000.0]          (45.0, inf]   \n",
       "2009-05-01 03:06:19    VA      6.214608  (0.0, 40000.0]         (29.0, 45.0]   \n",
       "2009-05-01 12:22:21    NY      7.600902  (0.0, 40000.0]         (29.0, 45.0]   \n",
       "2009-05-01 15:44:25    LA      8.294050  (0.0, 40000.0]         (29.0, 45.0]   \n",
       "\n",
       "                    weekday_launch  weekend_launch  month_launch  \\\n",
       "launched_at                                                        \n",
       "2009-04-28 11:55:41        Tuesday           False             4   \n",
       "2009-04-29 03:26:32      Wednesday           False             4   \n",
       "2009-04-29 20:08:13      Wednesday           False             4   \n",
       "2009-04-29 21:11:15      Wednesday           False             4   \n",
       "2009-04-29 23:32:55      Wednesday           False             4   \n",
       "2009-04-30 20:22:43       Thursday           False             4   \n",
       "2009-04-30 20:23:22       Thursday           False             4   \n",
       "2009-05-01 03:06:19         Friday           False             5   \n",
       "2009-05-01 12:22:21         Friday           False             5   \n",
       "2009-05-01 15:44:25         Friday           False             5   \n",
       "\n",
       "                     num_competitors num_competitors_bin  \\\n",
       "launched_at                                                \n",
       "2009-04-28 11:55:41              1.0         (0.0, 10.0]   \n",
       "2009-04-29 03:26:32              1.0         (0.0, 10.0]   \n",
       "2009-04-29 20:08:13              1.0         (0.0, 10.0]   \n",
       "2009-04-29 21:11:15              1.0         (0.0, 10.0]   \n",
       "2009-04-29 23:32:55              1.0         (0.0, 10.0]   \n",
       "2009-04-30 20:22:43              1.0         (0.0, 10.0]   \n",
       "2009-04-30 20:23:22              2.0         (0.0, 10.0]   \n",
       "2009-05-01 03:06:19              1.0         (0.0, 10.0]   \n",
       "2009-05-01 12:22:21              1.0         (0.0, 10.0]   \n",
       "2009-05-01 15:44:25              1.0         (0.0, 10.0]   \n",
       "\n",
       "                     num_competitors_staffpick  \n",
       "launched_at                                     \n",
       "2009-04-28 11:55:41                        1.0  \n",
       "2009-04-29 03:26:32                        0.0  \n",
       "2009-04-29 20:08:13                        0.0  \n",
       "2009-04-29 21:11:15                        1.0  \n",
       "2009-04-29 23:32:55                        0.0  \n",
       "2009-04-30 20:22:43                        1.0  \n",
       "2009-04-30 20:23:22                        1.0  \n",
       "2009-05-01 03:06:19                        1.0  \n",
       "2009-05-01 12:22:21                        0.0  \n",
       "2009-05-01 15:44:25                        1.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = read_from_disk(os.path.join(datadir, 'data_cleaned.pkl'))\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['staff_pick', 'result', 'ln(goal_usd)', 'main_category', 'state', 'duration_in_days_bin', \n",
    "           'weekday_launch', 'month_launch', 'num_competitors_bin']\n",
    "df = df[columns].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Standardize data and Dummy Variables\n",
    "\n",
    "First of all lets standardize only numeric columns of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.api.types import is_numeric_dtype\n",
    "\n",
    "y = df['result']\n",
    "X = df.drop('result', axis=1)\n",
    "num_cols = X.columns[X.dtypes.apply(lambda col: np.all([is_numeric_dtype(col),  col != 'bool']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agericke/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/agericke/anaconda3/lib/python3.7/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "scaler = preprocessing.StandardScaler()\n",
    "X[num_cols] = scaler.fit_transform(X[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['staff_pick'] = X['staff_pick'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(X, drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stratified splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=33, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  2. Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  2.0 NIR (No Informaiton Rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5531897274524621"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nir = np.mean(y)\n",
    "nir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb_scikit = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb_scikit.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = gnb_scikit.predict(X_test)\n",
    "y_train_pred = gnb_scikit.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on training data=0.6533373013\n",
      "accuracy on test data=0.6508293870\n"
     ]
    }
   ],
   "source": [
    "print('accuracy on training data={:.10f}'.format(accuracy_score(y_train_pred, y_train)))\n",
    "print('accuracy on test data={:.10f}'.format(accuracy_score(y_test_pred, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a Gaussian Naive Bayes classificator we will need to compute:\n",
    "\n",
    "1. P(y) - Prior probabilities\n",
    "2. P(x|y)\n",
    "3. P(y|x) - Posterior probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianNaiveBayes:\n",
    "    \"\"\"Naive Bayes text categorization model\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, unique_classes=[0]):\n",
    "        self.classes = np.array(unique_classes)\n",
    "        \n",
    "    \n",
    "    def fit(self, X, y):\n",
    "\n",
    "        self.examples = X\n",
    "        self.labels = y\n",
    "\n",
    "        self.prior_prob = X.groupby(y).apply(lambda x: float(len(x)) / float(X.shape[0])).to_numpy()\n",
    "\n",
    "        # Calculate per column means\n",
    "        self.means = X.groupby(y).aggregate(np.mean).to_numpy()\n",
    "        self.vars = X.groupby(y).aggregate(np.var).to_numpy()\n",
    "            \n",
    "    \n",
    "    def predict(self, X):\n",
    "        \n",
    "        y_pred = np.zeros(X.shape[0])\n",
    "        \n",
    "        probs = np.empty([X.shape[0], len(self.classes)])\n",
    "        \n",
    "        if not isinstance(X, np.ndarray): X = np.array(X)\n",
    "\n",
    "        for i, cl in enumerate(self.classes):\n",
    "            \n",
    "            # For efficiency purposes, we will perform first all per column values\n",
    "            #df_logs = pd.DataFrame().reindex_like(X)\n",
    "            #df_logs = X.apply(lambda col_values: self.calculate_log_probabilities(col_values, col_values.name, cl),\n",
    "            #                                      axis=0)\n",
    "            \n",
    "            prob = np.log(self.prior_prob[i])\n",
    "            cond_prob =  - 0.5 * np.sum(2. * np.pi * self.vars[i, :])\n",
    "            cond_prob -= 0.5 * np.sum((X - self.means[i, :]) ** 2 / (self.vars[i, :]), 1)\n",
    "            probs[:, cl] = prob + cond_prob\n",
    "            \n",
    "        #normalization_factor = self.log_sum(sum_positive, sum_negative)\n",
    "            #probs[:, cl] = df_logs.apply(lambda x: x.sum() + self.prior_prob[cl], axis=1)\n",
    "        \n",
    "        y_pred = self.classes[probs.argmax(axis=1)]\n",
    "\n",
    "        return y_pred\n",
    "    \n",
    "    \n",
    "    def log_sum(self, logx, logy):\n",
    "        \"\"\"Utility function to compute $log(exp(logx) + exp(logy))$\n",
    "        while avoiding numerical issues\n",
    "        \"\"\"\n",
    "        m = max(logx, logy)\n",
    "        return m + log(exp(logx - m) + exp(logy - m))\n",
    "    \n",
    "    \n",
    "    def calculate_log_probabilities(self, values, col_name, cl):\n",
    "        \"\"\"Calculate probabilities\n",
    "        \"\"\"\n",
    "        mean = self.col_means.loc[cl, col_name]\n",
    "        std = self.col_stds.loc[cl, col_name]\n",
    "        dist = norm(mean, std)\n",
    "        \n",
    "        return np.log(norm.pdf(values.values, mean, std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNaiveBayes([0, 1])\n",
    "gnb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = gnb.predict(X_test)\n",
    "y_train_pred = gnb.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on training data=0.6530914596\n",
      "accuracy on test data=0.6490179334\n"
     ]
    }
   ],
   "source": [
    "print('accuracy on training data={:.10f}'.format(accuracy_score(y_train_pred, y_train)))\n",
    "print('accuracy on test data={:.10f}'.format(accuracy_score(y_test_pred, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the Logistic Regression we will approach it in two methods:\n",
    "\n",
    "1. Only from a ML perspective using the scikit package. We will perform a GridSearch from scratch and using the GridSearchCV method. Then we will perform a model analysis, calculating ROC values, precision and recall, AUC values and analysing the top coefficients for both classes.\n",
    "\n",
    "2. We will introduce as well a statistics perspective for analysing the statistical importance of each coefficient and will try to optimize the model by prunning certain variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 ML Log. Regresion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Log. Regression.\n",
    "\n",
    "Perform a simple Logistic Regression to obtain an accuracy threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agericke/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='auto',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_scikit = LogisticRegression(solver='lbfgs', multi_class='auto')\n",
    "lr_scikit.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on training data=0.7047635067\n",
      "accuracy on test data=0.7022229123\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = lr_scikit.predict(X_test)\n",
    "y_train_pred = lr_scikit.predict(X_train)\n",
    "print('accuracy on training data={:.10f}'.format(accuracy_score(y_train_pred, y_train)))\n",
    "print('accuracy on test data={:.10f}'.format(accuracy_score(y_test_pred, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Tunning\n",
    "\n",
    "Lets analyse the different combinations of options for finding the best parameter configuration for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a LogsticRegression object.\n",
    "def get_clf(penalty='l2', c=1, fit_intercept=True, solver='lbfgs', multi_class='auto',\n",
    "            max_iter=200, random_state=42, **kwds):\n",
    "    \"\"\"Function for creating a Logistic Regression object.\n",
    "    \n",
    "    Args:\n",
    "        penalty........Penalty type to be used by the Logistic Regression.\n",
    "        c..............C value for the regression.\n",
    "        solver.........Type of solver.\n",
    "        fit_intercept..Bool to indicate whther to fit or not the intercept.\n",
    "        multi_class....Specify type of multi_class to be used.\n",
    "        max_iter.......Maximum number of iterations taken for the solvers to converge.\n",
    "        random_state...RandomState instance.\n",
    "        \n",
    "    Returns:\n",
    "        A Logistic Regression classifier with the specified parameters.\n",
    "    \"\"\"\n",
    "    #print(\"get clf: {}\".format(kwds))\n",
    "    #print(\"C value = {}\".format(c))\n",
    "    return LogisticRegression(penalty=penalty, C=c, fit_intercept=fit_intercept, solver=solver, \n",
    "                              multi_class=multi_class, max_iter=max_iter, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-fold cross-validation accuracy\n",
    "def deviance(X, y, model):\n",
    "    \"\"\" Calculate the deviance for each model.\n",
    "    \"\"\"\n",
    "    return 2*log_loss(y, model.predict_proba(X), normalize=False)\n",
    "\n",
    "def do_cross_validation(X, y, X_val, y_val, n_folds=5, verbose=False, random_state=42, **kwds):\n",
    "    \"\"\"Perform a cross-validation accuracy.\n",
    "    \n",
    "    Args:\n",
    "        X.....................Training set matrix without the y value.\n",
    "        y.....................Class value for the training set.\n",
    "        X_val.................Validation set matrix without the y value.\n",
    "        y_val.................Class value for the validation set.\n",
    "        n_folds...............Number of folds to be performed by the cross-validation.\n",
    "        verbose...............Whether to print mid-results.\n",
    "        random_state..........RandomState instance.\n",
    "        **kwds................Other keyword arguments for the model.\n",
    "    \n",
    "    Returns:\n",
    "        Tuple containing accuracies and SD for the train sets, test sets and validation sets.\n",
    "    \"\"\"\n",
    "    #print(\"cross val: {}\".format(kwds))\n",
    "    cv = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=random_state)\n",
    "    val_accuracies = []\n",
    "    train_accuracies = []\n",
    "    test_accuracies = []\n",
    "    deviances = []\n",
    "    \n",
    "    for foldi, (train_ind, test_ind) in enumerate(cv.split(X, y)):\n",
    "        # Create Classification Model\n",
    "        model = get_clf(random_state=random_state, **kwds)\n",
    "        # Fit model\n",
    "        model.fit(X[train_ind, :], y[train_ind])\n",
    "        # Perform accuracy on train set\n",
    "        train_accuracies.append(accuracy_score(model.predict(X[train_ind]), y[train_ind]))\n",
    "        # Predict on test set and perform accuracy\n",
    "        acc = accuracy_score(y[test_ind], model.predict(X[test_ind, :]))\n",
    "        test_accuracies.append(acc)\n",
    "        # Predict on validation set and perform accuracy.\n",
    "        val_accuracies.append(accuracy_score(y_val, model.predict(X_val)))\n",
    "        if verbose:\n",
    "            print('fold %d accuracy=%.4g' % (foldi, acc))\n",
    "        deviances.append(deviance(X_val, y_val, model))\n",
    "\n",
    "    return (np.mean(test_accuracies), np.std(test_accuracies) / math.sqrt(n_folds),\n",
    "            np.mean(train_accuracies), np.std(train_accuracies) / math.sqrt(n_folds),\n",
    "            np.mean(val_accuracies), np.std(val_accuracies) / math.sqrt(n_folds),\n",
    "            np.mean(deviances), np.std(deviances) / math.sqrt(n_folds)\n",
    "           )\n",
    "\n",
    "def print_results(results):\n",
    "    print('test accuracy=%.4f (%.2f) train accuracy=%.4f (%.2f) validation accuracy=%.4f (%.2f) deviance=%.4f (%.2f)' % \n",
    "           results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_all_opts():\n",
    "    \"\"\"\n",
    "    Enumerate all possible classifier settings and compute.\n",
    "    \"\"\"\n",
    "    penalty = ['l2']\n",
    "    fit_intercept = [True, False]\n",
    "    argnames = ['penalty', 'fit_intercept']\n",
    "    option_iter = product(penalty, fit_intercept)\n",
    "    return argnames, option_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_all_combinations(X_train, y_train, X_test, y_test, n_folds=5, verbose=False, c_eval=False,\n",
    "                          cs=[], **kwds):\n",
    "    \"\"\"Evaluate all combinations of options.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    if len(cs) > 0:\n",
    "        for c in cs:\n",
    "            #print(\"eval comb: {}\".format(kwds))\n",
    "            accs = do_cross_validation(X_train.to_numpy(), y_train.to_numpy(), X_test.to_numpy(),\n",
    "                                       y_test.to_numpy(), n_folds=n_folds, verbose=verbose, c=c, **kwds)\n",
    "            opts = kwds.copy()\n",
    "            opts['c'] = c\n",
    "            results.append((accs, opts))\n",
    "        results_sorted = sorted(results, key=lambda x: (-x[0][4], -x[0][0], -x[0][2]))\n",
    "    else:\n",
    "        argnames, option_iter = generate_all_opts()\n",
    "        for options in option_iter:\n",
    "            opts = {name: opt for name, opt in zip(argnames, options)}\n",
    "            accs = do_cross_validation(X_train.to_numpy(), y_train.to_numpy(), X_test.to_numpy(),\n",
    "                                          y_test.to_numpy(), n_folds=n_folds, verbose=verbose, **opts)\n",
    "            results.append((accs, opts))\n",
    "        results_sorted = sorted(results, key=lambda x: (-x[0][4], x[0][6], -x[0][0], -x[0][2]))\n",
    "    return results_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-c257faf76d8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_all_combinations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbest_opts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best options are {} with accuracy={:.2%}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-a7fe0a85ca3d>\u001b[0m in \u001b[0;36meval_all_combinations\u001b[0;34m(X_train, y_train, X_test, y_test, n_folds, verbose, c_eval, cs, **kwds)\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mopts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             accs = do_cross_validation(X_train.to_numpy(), y_train.to_numpy(), X_test.to_numpy(),\n\u001b[0;32m---> 21\u001b[0;31m                                           y_test.to_numpy(), n_folds=n_folds, verbose=verbose, **opts)\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mresults_sorted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-8cf45683a2e0>\u001b[0m in \u001b[0;36mdo_cross_validation\u001b[0;34m(X, y, X_val, y_val, n_folds, verbose, random_state, **kwds)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_clf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m# Fit model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_ind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;31m# Perform accuracy on train set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mtrain_accuracies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_ind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_ind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1361\u001b[0m                       \u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1362\u001b[0m                       sample_weight=sample_weight)\n\u001b[0;32m-> 1363\u001b[0;31m             for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n\u001b[0m\u001b[1;32m   1364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0mfold_coefs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfold_coefs_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    915\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mlogistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight)\u001b[0m\n\u001b[1;32m    753\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfprime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 755\u001b[0;31m                 iprint=iprint, pgtol=tol, maxiter=max_iter)\n\u001b[0m\u001b[1;32m    756\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"warnflag\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m                 warnings.warn(\"lbfgs failed to converge. Increase the number \"\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36mfmin_l_bfgs_b\u001b[0;34m(func, x0, fprime, args, approx_grad, bounds, m, factr, pgtol, epsilon, iprint, maxfun, maxiter, disp, callback, maxls)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     res = _minimize_lbfgsb(fun, x0, args=args, jac=jac, bounds=bounds,\n\u001b[0;32m--> 199\u001b[0;31m                            **opts)\n\u001b[0m\u001b[1;32m    200\u001b[0m     d = {'grad': res['jac'],\n\u001b[1;32m    201\u001b[0m          \u001b[0;34m'task'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'message'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, **unknown_options)\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0;31m# Overwrite f and g:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'NEW_X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0;31m# new iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36mfunc_and_grad\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m             \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*wrapper_args)\u001b[0m\n\u001b[1;32m    298\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36m_logistic_loss_and_grad\u001b[0;34m(w, X, y, alpha, sample_weight)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;31m# Logistic loss is the negative of the log of the logistic function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlog_logistic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results = eval_all_combinations(X_train, y_train, X_test, y_test, verbose=False)\n",
    "best_opts = results[0][1]\n",
    "print(\"Best options are {} with accuracy={:.2%}\".format(results[0][1], results[0][0][4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best c value\n",
    "cs = [.001, .01, .1, 1, 5, 10, 1000, 10000]\n",
    "results = eval_all_combinations(X_train, y_train, X_test, y_test, verbose=False,\n",
    "                                cs=cs, **best_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracies(results):\n",
    "    \"\"\"Plot accuracies for the different c values.\n",
    "    \"\"\"\n",
    "    #Sort results according to c values\n",
    "    results = sorted(results, key=lambda x: (x[1]['c']))\n",
    "    accs = [result[0] for result in results]\n",
    "    opts = [result[1] for result in results]\n",
    "    cs = [opt['c'] for opt in opts]\n",
    "    test_accs = [acc[0] for acc in accs]\n",
    "    test_sd = [acc[1] for acc in accs]\n",
    "    train_accs = [acc[2] for acc in accs]\n",
    "    train_sd = [acc[3] for acc in accs]\n",
    "    val_accs = [acc[4] for acc in accs]\n",
    "    val_sd = [acc[5] for acc in accs]\n",
    "    dev = [acc[6] for acc in accs]\n",
    "    dev_sd = [acc[7] for acc in accs]\n",
    "    \n",
    "    # plot accuracies\n",
    "    plt.figure()\n",
    "    plt.errorbar(cs, train_accs, fmt='go-', label='train acc', yerr=train_sd)\n",
    "    plt.errorbar(cs, test_accs, fmt='bo-', label='test acc', yerr=test_sd)\n",
    "    plt.errorbar(cs, val_accs, fmt='ro-', label='val acc', yerr=val_sd)\n",
    "    plt.xlabel('C')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xscale('log')\n",
    "    plt.title(\"Accuracies with different C values.\")\n",
    "    plt.ylim([0.68, 0.75])\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    # plot deviance values\n",
    "    plt.figure()\n",
    "    plt.errorbar(cs, dev, fmt='ro-', label='deviance vals', yerr=dev_sd)\n",
    "    plt.xlabel('C')\n",
    "    plt.ylabel('deviance')\n",
    "    plt.xscale('log')\n",
    "    plt.title(\"Deviance Values with different C values.\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_accuracies(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [x] Select model evaluation crieria. - Accuracy Score + Deviance\n",
    "    - [x] ROC curve.\n",
    "    - [x] AUC values.\n",
    "2. [x] Model evaluation with GridSearch.\n",
    "3. [x] Model Performance analysis.\n",
    "4. [ ] Model tunning with statistics.\n",
    "    - [ ] Model evaluation comparison.\n",
    "    - [ ] From scratch model backwards and forward selection.\n",
    "5. [ ] Model Summary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Select Best Model.\n",
    "\n",
    "Fit a model with the best parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results are already sorted by val_acc, then test acc and finally train acc.\n",
    "best_opts = results[0][1]\n",
    "print('Best options are {}'.format(best_opts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = get_clf(**best_opts)\n",
    "lr_model.fit(X_train.to_numpy(), y_train.to_numpy())\n",
    "y_pred = lr_model.predict(X_test.to_numpy())\n",
    "print(\"Test Accuracy {:.4%}\".format(accuracy_score(y_pred, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Analysis using GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = [.001, .01, .1, 1, 5, 10, 1000, 10000]\n",
    "parameters = {'penalty': ['l2'], 'C':cs, 'fit_intercept': [True]}\n",
    "model = LogisticRegression(solver='lbfgs', random_state=42, max_iter=200)\n",
    "grid = GridSearchCV(model, parameters, cv=5)\n",
    "grid.fit(X_train.to_numpy(), y_train.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best parameters found with GridSearch Function: {}'.format(grid.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = grid.best_estimator_\n",
    "lr_model.fit(X_train.to_numpy(), y_train.to_numpy())\n",
    "y_pred = lr_model.predict(X_test.to_numpy())\n",
    "y_pred_prob = lr_model.predict_proba(X_test.to_numpy())\n",
    "\n",
    "print(\"Test Accuracy {:.4%}\".format(accuracy_score(y_pred, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the best parameters coincide with the ones that we found."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets analyze the terms more related to the different classes.\n",
    "# Coefficients for the positive class\n",
    "coef = lr_model.coef_[0]\n",
    "cols =  X_train.columns\n",
    "srted = np.argsort(coef)\n",
    "# Pick top 10 coef. in descendent order\n",
    "topi = srted[::-1][:10]\n",
    "boti = srted[:10]\n",
    "print('Successful Terms:\\n' + '\\n'.join('%s (%g)' % (n, c) for n, c in zip(cols[topi], coef[topi])))\n",
    "print('\\nFail Terms:\\n' + '\\n'.join('%s (%g)' % (n, c) for n, c in zip(cols[boti], coef[boti])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets analyze the confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test.to_numpy(), y_pred)\n",
    "\n",
    "class_names=['fail','successful'] # name  of classes\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "tick_marks = np.arange(len(class_names))\n",
    "plt.xticks(tick_marks, class_names)\n",
    "plt.yticks(tick_marks, class_names)\n",
    "# create heatmap\n",
    "sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
    "ax.xaxis.set_label_position(\"top\")\n",
    "plt.tight_layout()\n",
    "plt.title('Confusion matrix', y=1.1)\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy Score: {:.2%}\".format(accuracy_score(y_test, y_pred)))\n",
    "print(\"Precision Score: {:.2%}\".format(precision_score(y_test, y_pred)))\n",
    "print(\"Recall Score: {:.2%} \\n\".format(recall_score(y_test, y_pred)))\n",
    "print(classification_report(y_test, y_pred, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets take a look at the ROC curve.\n",
    "ns_probs = [1 for _ in range(len(y_test))] # No skill predictor\n",
    "# Keep only probabilities for Successful class\n",
    "y_pred_prob_pos = y_pred_prob[:, 1]\n",
    "# Calculate ROC scores\n",
    "ns_roc = roc_auc_score(y_test, ns_probs)\n",
    "model_roc = roc_auc_score(y_test, y_pred_prob_pos)\n",
    "print(\"No Skill: ROC AUC = {:.3f}\".format(ns_roc))\n",
    "print(\"Logistic: ROC AUC = {:.3f}\".format(model_roc))\n",
    "\n",
    "# Calculate roc curves\n",
    "ns_fpr, ns_tpr, thresholds = roc_curve(y_test, ns_probs)\n",
    "model_fpr, model_tpr, thresholds = roc_curve(y_test, y_pred_prob_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate precision-recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test.to_numpy(), y_pred_prob_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Roc Curves\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "plt.plot(model_fpr, model_tpr, color='darkorange',lw=2, label='ROC curve (area = {:.2f})'.format(model_roc))\n",
    "plt.plot(ns_fpr, ns_tpr, color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating Characteristic curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 6))\n",
    "plt.plot(precision, recall, label='Prec-Recall')\n",
    "#plt.xlim([0.0, 1.0])\n",
    "#plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Precision')\n",
    "plt.ylabel('Recall')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recursive Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lr_model.coef_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfecv = RFECV(estimator=grid.best_estimator_, step=2, cv=StratifiedKFold(5))\n",
    "rfecv.fit(X_train.to_numpy(), y_train.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Optimal number of features : %d\" % rfecv.n_features_)\n",
    "\n",
    "# Plot number of features VS. cross-validation scores\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score (# of correct classifications)\")\n",
    "plt.plot(range(1, len(rfecv.support_) + 2, 2), rfecv.grid_scores_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Statistics Analysis\n",
    "\n",
    "For performing also a statistical analysis on the model and its parameters we will use the package stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_formula(target_var, x_vars, include_intercept=True):\n",
    "    \"\"\"Function for creating a formula.\n",
    "    \n",
    "    Args:\n",
    "        target_var..........Dependent variable.\n",
    "        x_vars..............List of independent variable.\n",
    "        include_intercept...Bool to indicate whether to include or not the intercept.\n",
    "    Returns:\n",
    "        A string representing the formula to be passed.\n",
    "    \"\"\"\n",
    "    if include_intercept:\n",
    "        separator = \" + \"\n",
    "        model_form = target_var + \" ~ \" + separator.join(x_vars)\n",
    "    else:\n",
    "        separator = \" + \"\n",
    "        model_form = target_var + \" ~ \" + separator.join(x_vars) + \" - 1\"\n",
    "    \n",
    "    return model_form\n",
    "\n",
    "\n",
    "def remove_vars_from_formula(formula, vars_to_remove):\n",
    "    \"\"\"Remove specific vars from the formula.\n",
    "    \n",
    "    Args:\n",
    "        formula...........Formula to be applied in the model.\n",
    "        args_to_remove....List of variables to remove from the formula.\n",
    "    \n",
    "    Returns:\n",
    "        A string representing the formula.\n",
    "    \"\"\"\n",
    "    separator = \" - \"\n",
    "    model_form = formula + separator + separator.join(vars_to_remove)\n",
    "    \n",
    "    return model_form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = pd.concat([y_train, X_train], axis=1)\n",
    "df_model.rename(\n",
    "    columns={'ln(goal_usd)': 'ln_goal_usd', 'main_category_film-&-video': 'main_category_film_video',\n",
    "             #'duration_in_days_bin_(0.0, 29.0]': 'duration_in_days_low',\n",
    "             'duration_in_days_bin_(29.0, 45.0]': 'duration_in_days_medium',\n",
    "             'duration_in_days_bin_(45.0, inf]': 'duration_in_days_high',\n",
    "             #'num_competitors_bin_(0.0, 10.0]': 'num_competitors_low',\n",
    "             'num_competitors_bin_(10.0, 30.0]': 'num_competitors_medium',\n",
    "             'num_competitors_bin_(30.0, inf]': 'num_competitors_high'},\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "target_var = 'result'\n",
    "x_vars = [col for col in df_model.columns if col != target_var]\n",
    "model_form = create_model_formula(target_var, x_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_stats = smf.glm(formula=model_form, data=df_model, family=sm.families.Binomial()).fit(method='lbfgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_stats.summary2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_lr = X_train.rename(\n",
    "    columns={'ln(goal_usd)': 'ln_goal_usd', 'main_category_film-&-video': 'main_category_film_video',\n",
    "             #'duration_in_days_bin_(0.0, 29.0]': 'duration_in_days_low',\n",
    "             'duration_in_days_bin_(29.0, 45.0]': 'duration_in_days_medium',\n",
    "             'duration_in_days_bin_(45.0, inf]': 'duration_in_days_high',\n",
    "             #'num_competitors_bin_(0.0, 10.0]': 'num_competitors_low',\n",
    "             'num_competitors_bin_(10.0, 30.0]': 'num_competitors_medium',\n",
    "             'num_competitors_bin_(30.0, inf]': 'num_competitors_high'}\n",
    ")\n",
    "X_test_lr = X_test.rename(\n",
    "    columns={'ln(goal_usd)': 'ln_goal_usd', 'main_category_film-&-video': 'main_category_film_video',\n",
    "             #'duration_in_days_bin_(0.0, 29.0]': 'duration_in_days_low',\n",
    "             'duration_in_days_bin_(29.0, 45.0]': 'duration_in_days_medium',\n",
    "             'duration_in_days_bin_(45.0, inf]': 'duration_in_days_high',\n",
    "             #'num_competitors_bin_(0.0, 10.0]': 'num_competitors_low',\n",
    "             'num_competitors_bin_(10.0, 30.0]': 'num_competitors_medium',\n",
    "             'num_competitors_bin_(30.0, inf]': 'num_competitors_high'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = lr_stats.predict(X_train_lr)\n",
    "y_train_pred = y_train_pred.apply(lambda x: 1 if x > 0.5 else 0)\n",
    "y_test_pred = lr_stats.predict(X_test_lr)\n",
    "y_test_pred = y_test_pred.apply(lambda x: 1 if x > 0.5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy on training data={:.10f}'.format(accuracy_score(y_train_pred, y_train)))\n",
    "print('Accuracy on test data={:.10f}'.format(accuracy_score(y_test_pred, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stepwise selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_form = create_model_formula('result', '1')\n",
    "lr_stats_null = smf.glm(formula=model_form, data=df_model, family=sm.families.Binomial()).fit(method='lbfgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets drop variables until all variables are significant at a given cutoff (alpha).\n",
    "alpha = .005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_selection(data, response, X_test, y_test, max_iter=10, alpha=0.05, verbose=False):\n",
    "    \"\"\"Linear model designed for backwards selection.\n",
    "\n",
    "    Args:\n",
    "        data..........pandas DataFrame with all possible predictors and response.\n",
    "        response......name of response column in data.\n",
    "        X_test........Test set for computing accuracy of the model.\n",
    "        y_test........Array of Test set actual labels.\n",
    "        max_iter......Maximum number of removals.\n",
    "        alpha.........Confidence threshold cutoff.\n",
    "\n",
    "    Returns:\n",
    "        model.........The final obtained model.\n",
    "        removed_cols..Dict containing remove cols and their p-values.\n",
    "        results.......Dict containing results on each interaction.\n",
    "    \"\"\"    \n",
    "    x_vars = set(data.columns)\n",
    "    x_vars.remove(response)\n",
    "    removed_cols = [] # list of dicts containing {col_name: p_value}\n",
    "    results = [] #list with dicts containing {formula: , accuracy_on_test: , aic}\n",
    "\n",
    "    # Run model with all variables\n",
    "    model_form = create_model_formula(response, x_vars)\n",
    "    if verbose:\n",
    "        print(\"Running model with formula: \\n{}\".format(model_form))\n",
    "    lr_stats = smf.glm(formula=model_form, data=data, family=sm.families.Binomial()).fit(method='lbfgs')\n",
    "    # Compute Accuracy\n",
    "    y_test_pred = lr_stats.predict(X_test)\n",
    "    y_test_pred = y_test_pred.apply(lambda x: 1 if x > 0.5 else 0)\n",
    "    test_acc = accuracy_score(y_test_pred, y_test)\n",
    "    results.append({'formula': model_form, 'test_accuracy': test_acc, 'aic': lr_stats.aic})\n",
    "    \n",
    "    p_values = lr_stats.pvalues.sort_values(ascending=False)\n",
    "    if verbose:\n",
    "            print(\"\\nTest Accuracy: {}\".format(test_acc))\n",
    "            print(\"\\nAIC: {}\".format(lr_stats.aic))\n",
    "            print(\"\\nBiggest p-value: {}:{}\".format(p_values.index[0], p_values[0]))\n",
    "    \n",
    "    while (p_values[0] > alpha) and (len(removed_cols) <= max_iter):\n",
    "        \n",
    "        removed_cols.append({p_values.index[0]: p_values[0]})\n",
    "        print(removed_cols)\n",
    "        model_form = remove_vars_from_formula(model_form, [p_values.index[0]])\n",
    "        if verbose and len(removed_cols)>1:\n",
    "            print(\"\\n\\nRunning model with formula: \\n{}\".format(model_form))\n",
    "        \n",
    "        lr_stats = smf.glm(formula=model_form, data=data, family=sm.families.Binomial()).fit(method='lbfgs')\n",
    "        y_test_pred = lr_stats.predict(X_test)\n",
    "        y_test_pred = y_test_pred.apply(lambda x: 1 if x > 0.5 else 0)\n",
    "        test_acc = accuracy_score(y_test_pred, y_test)\n",
    "        results.append({'formula': model_form, 'test_accuracy': test_acc, 'aic': lr_stats.aic})\n",
    "        if verbose:\n",
    "            print(\"\\nTest Accuracy: {}\".format(test_acc))\n",
    "            print(\"\\nAIC: {}\".format(lr_stats.aic))\n",
    "            print(\"\\nBiggest p-value: {}:{}\".format(p_values.index[0], p_values[0]))\n",
    "        \n",
    "        p_values = lr_stats.pvalues.sort_values(ascending=False)\n",
    "        \n",
    "    return lr_stats, removed_cols, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_stats, removed_cols, results = backward_selection(df_model, target_var, X_test_lr, y_test,\n",
    "                                                     alpha=alpha, max_iter = 100, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = [result['test_accuracy'] for result in results]\n",
    "plt.plot(range(len(accs)), accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aic = [result['aic'] for result in results]\n",
    "plt.plot(range(len(aic)), aic)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
